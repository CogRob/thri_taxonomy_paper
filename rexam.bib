@TECHREPORT{Balch98taxonomies,
    author = {Tucker Balch},
    title = {Taxonomies of Multirobot Task and Reward},
    institution = {In},
    year = {1998}
}
@article{Goodrich2007,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Goodrich, Michael A. and Schultz, Alan C.},
isbn = {9781601980922},
issn = {1551-3955},
journal = {Foundations and Trends\textsuperscript{\textregistered} in Human-Computer Interaction},
keywords = {survey,taxonomy},
mendeley-tags = {survey,taxonomy},
number = {3},
pages = {203--275},
pmid = {25052830},
title = {{Human-Robot Interaction: A Survey}},
volume = {1},
year = {2007}
}
@inproceedings{Yanco2004updated, 
author={H. A. Yanco and J. Drury}, 
booktitle={2004 IEEE International Conference on Systems, Man and Cybernetics}, 
title={Classifying human-robot interaction: an updated taxonomy}, 
year={2004}, 
volume={3}, 
pages={2841-2846 vol.3}, 
keywords={robots;man-machine systems;user interfaces;updated taxonomy;human-robot interaction;robot morphology;human-robot physical proximity;human interaction roles;Taxonomy;Collaboration;Robot sensing systems;Human robot interaction;Collaborative work;Application software;Control systems;Sensor systems;Computer science;Teleconferencing}, 
doi={10.1109/ICSMC.2004.1400763}, 
ISSN={1062-922X}, 
month={Oct},}
@ARTICLE{Dudek96,
    author = {Gregory Dudek and Michael R. M. Jenkin and Evangelos Milios and David Wilkes},
    title = {A taxonomy for multi-agent robotics},
    journal = {AUTONOMOUS ROBOTS},
    year = {1996},
    volume = {3},
    pages = {375--397}
}
@article{Dudek2002updated,
  title={A taxonomy of multirobot systems},
  author={Dudek, Gregory and Jenkin, Michael and Milios, Evangelos},
  journal={Robot teams: From diversity to polymorphism},
  pages={3--22},
  year={2002},
  publisher={Natick, MA: AK Peters}
}
@article{Burke2004,
author = {Burke, Jennifer L. and Murphy, Robin Roberson and Rogers, Erika and Lumelsky, Vladimir J. and Scholtz, Jean},
doi = {10.1109/TSMCC.2004.826287},
issn = {10946977},
journal = {IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews},
keywords = {Man-machine systems,Mobile robots,Research and development,Technology social factors,taxonomy},
mendeley-tags = {taxonomy},
number = {2},
pages = {103--112},
title = {{Final report for the DARPA/NSF interdisciplinary study on human-robot interaction}},
volume = {34},
year = {2004}
}
@article{Dautenhahn,
abstract = {Social intelligence in robots has a quite recent history in artificial intelligence and robotics. However, it has become increasingly apparent that social and interactive skills are necessary requirements in many application areas and contexts where robots need to interact and collaborate with other robots or humans. Research on human-robot interaction (HRI) poses many challenges regarding the nature of interactivity and 'social behaviour' in robot and humans. The first part of this paper addresses dimensions of HRI, discussing requirements on social skills for robots and introducing the conceptual space of HRI studies. In order to illustrate these concepts, two examples of HRI research are presented. First, research is surveyed which investigates the development of a cognitive robot companion. The aim of this work is to develop social rules for robot behaviour (a 'robotiquette') that is comfortable and acceptable to humans. Second, robots are discussed as possible educational or therapeutic toys for children with autism. The concept of interactive emergence in human-child interactions is highlighted. Different types of play among children are discussed in the light of their potential investigation in human-robot experiments. The paper concludes by examining different paradigms regarding 'social relationships' of robots and people interacting with them.},
author = {Dautenhahn, Kerstin},
doi = {10.1098/rstb.2006.2004},
file = {::},
keywords = {human-robot interaction,robot companion,robotiquette,social robots,taxonomy},
mendeley-tags = {taxonomy},
title = {{Socially intelligent robots: dimensions of human-robot interaction}},
url = {http://commons.wikimedia.org/wiki/Image:}
}
@techreport{Steinfeld2006,
abstract = {This paper describes an effort to identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing the need for a toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors that must be taken into consideration. Finally, we present suggested common metrics for standardization and a case study. Preparation of a larger, more detailed toolkit is in progress.},
author = {Steinfeld, Aaron and Fong, Terrence and Kaber, David and Lewis, Michael and Scholtz, Jean and Schultz, Alan and Goodrich, Michael},
file = {::},
keywords = {Design,Experimentation,Human Factors,I29 [Artificial Intelligence]: Robotics-operator i,Performance,Standardization Keywords Human-robot interaction,metrics,taxonomy,unmanned ground vehicles},
mendeley-tags = {taxonomy},
title = {{Common Metrics for Human-Robot Interaction}},
url = {http://www.dtic.mil/dtic/tr/fulltext/u2/a633755.pdf},
year = {2006}
}
@article{Beer2014toward,
  title={Toward a framework for levels of robot autonomy in human-robot interaction.},
  author={Jenay M. Beer and Arthur D. Fisk and Wendy A. Rogers},
  journal={Journal of human-robot interaction},
  year={2014},
  volume={3 2},
  pages={74-99}
}
@article{Goodrich,
annote = {There was switching cost associated in switching from some secondary task to the primary task. Moreover, different kinds of secondary tasks had varying length of switching cost time. Therefore, before employing feasibility/non-feasibility tests on human-robot teams, the task itself needs to be understood better to benchmark the switching costs of various human-monitors.},
author = {Goodrich, Michael A. and Quigley, Morgan and Cosenzo, Keryl},
doi = {10.1007/1-4020-3389-3_15},
isbn = {1078-8956 (Print)$\backslash$r1078-8956 (Linking)},
issn = {1078-8956},
journal = {Multi-Robot Systems. From Swarms to Intelligent Automata Volume III},
keywords = {multi-robot,multi-task},
mendeley-tags = {multi-robot,multi-task},
pages = {185--195},
pmid = {16288282},
title = {{Task Switching and Multi-Robot Teams}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F1-4020-3389-3.pdf},
volume = {III}
}
@article{Skubic2007,
abstract = {In this paper, we describe a prototype interface that facilitates the control of a mobile robot team by a single operator, using a sketch interface on a tablet PC. The user sketches a qualitative map of the scene and includes the robots in approximate starting positions. Both path and target position commands are supported as well as editing capabilities. Sensor feedback from the robots is included in the display such that the sketch interface acts as a two-way communication device between the user and the robots. The paper also includes results of a usability study, in which users were asked to perform a series of tasks},
author = {Skubic, Marjorie and Anderson, Derek and Blisard, Samuel and Perzanowski, Dennis and Schultz, Alan},
doi = {10.1007/s10514-007-9023-1},
isbn = {0780395069},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {Human-robot interaction,Qualitative map,Sketch-based navigation,taxonomy},
mendeley-tags = {taxonomy},
number = {4},
pages = {399--410},
title = {{Using a hand-drawn sketch to control a team of robots}},
volume = {22},
year = {2007}
}
@article{Nourbakhsh2005,
abstract = {This work establishes an architecture for Urban Search and Rescue and a methodology for mixing real-world and simulation-based testing. A sensor suite and sensor fusion algorithm for robust victim detection permits aggregation of sensor readings from various sensors on multiple robots. We have embarked on a research program focusing on the enabling technologies of effective USAR robotic rescue devices. The program is also researching system-level design, evaluation, and refinement of USAR rescue architectures that include teams of sensor-laden robots and human rescuers. In this paper, we present highlights from our research, which include our multiagent system (MAS) infrastructure, our simulation environment, and our approach to sensor fusion and interface design for effective robotic control.},
author = {Nourbakhsh, Illah R. and Sycara, Katia and Koes, Mary and Yong, Mark and Lewis, Michael and Burion, Steve},
doi = {10.1109/MPRV.2005.13},
isbn = {1536-1268},
issn = {15361268},
journal = {IEEE Pervasive Computing},
keywords = {taxonomy},
mendeley-tags = {taxonomy},
number = {1},
pages = {72--77},
title = {{Human-robot teaming for Search and Rescue}},
volume = {4},
year = {2005}
}
@article{Mitchell2002,
author = {Mitchell, P.J. and Cummings, Mary L.},
isbn = {0780372727},
keywords = {MSEC2017-3125,taxonomy},
mendeley-tags = {taxonomy},
number = {617},
pages = {1--6},
title = {{MANAGEMENT OF MULTIPLE DYNAMIC HUMAN SUPERVISORY CONTROL TASKS}},
url = {http://www.nowpublishers.com/article/Details/HCI-005},
volume = {02139},
year = {2002}
}
@article{Thomaz2016,
abstract = {Computational Human-Robot Interaction},
author = {Thomaz, Andrea and Hoffman, Guy and Cakmak, Maya},
doi = {10.1561/2300000049},
isbn = {978-1-68083-208-2},
issn = {1935-8253},
journal = {Foundations and Trends in Robotics},
keywords = {survey,taxonomy},
mendeley-tags = {survey,taxonomy},
number = {2-3},
pages = {104--223},
title = {{Computational Human-Robot Interaction}},
url = {http://www.nowpublishers.com/article/Details/ROB-049},
volume = {4},
year = {2016}
}
@article{Sellner2006,
abstract = {Recent research in human-robot interaction has investigated the concept of Sliding, or Adjustable, Autonomy, a mode of operation bridging the gap between explicit teleoperation and complete robot autonomy. This work has largely been in single-agent domains-involving only one human and one robot-and has not examined the issues that arise in multiagent domains. We discuss the issues involved in adapting Sliding Autonomy concepts to coordinated multiagent teams. In our approach, remote human operators have the ability to join, or leave, the team at will to assist the autonomous agents with their tasks (or aspects of their tasks) while not disrupting the team's coordination. Agents model their own and the human operator's performance on subtasks to enable them to determine when to request help from the operator. To validate our approach, we present the results of two experiments. The first evaluates the human/multirobot team's performance under four different collaboration strategies including complete teleoperation, pure autonomy, and two distinct versions of Sliding Autonomy. The second experiment compares a variety of user interface configurations to investigate how quickly a human operator can attain situational awareness when asked to help. The results of these studies support our belief that by incorporating a remote human operator into multiagent teams, the team as a whole becomes more robust and efficient},
author = {Sellner, Brennan and Heger, Frederik W. and Hiatt, Laura M. and Simmons, Reid and Singh, Sanjiv},
doi = {10.1109/JPROC.2006.876966},
isbn = {00189219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Architectures,Assembly,Autonomy,Experiments,Human-robot interaction,Multiagent systems,Sliding autonomy,Teleoperation,User modeling,mixed team,multi-robot,taxonomy},
mendeley-tags = {mixed team,multi-robot,taxonomy},
number = {7},
pages = {1425--1443},
title = {{Coordinated multiagent teams and sliding autonomy for large-scale assembly}},
volume = {94},
year = {2006}
}
@article{Wang2004,
abstract = {Many hypothesized application of mobil robotics require multiple robots. Multiple robots substantially increase the complexity of the operator's task because attention must be $\backslash$ncontinually shifted among robots. One approach to increasing human capacity for control is to remove the independence among robots by allowing them to cooperate. This paper presents an initial experiment using multiagent teamwork proxies to help control robots performing a search and rescue task.},
author = {Wang, J. and Lewis, M. and Scerri, P.},
doi = {10.1.1.119.8181},
journal = {Proceedings of AAAMAS 2006},
keywords = {Experimentation,Human Factors,Human-Robot Interaction,Multiagent Systems,Multirobot Systems,multi-robot,taxonomy},
mendeley-tags = {multi-robot,taxonomy},
title = {{Cooperating Robots for Search and Rescue}},
url = {http://scholar.google.com/scholar?q=intitle:Cooperating+Robots+for+Search+and+Rescue{\#}0},
year = {2004}
}
@article{Kaminka2006,
abstract = {Many robotics applications require a human operator$\backslash$nto monitor multiple robots that collaborate to achieve the$\backslash$noperator's goals. Most approaches to such monitoring focus on$\backslash$neach robot independently of its peers. When robots are tightlycoordinated,$\backslash$nthe operator is thus cognitively burdened to build$\backslash$na mental picture of the state of coordination. We report on$\backslash$nextensive experiments (approximately 100 hours) with up to 25$\backslash$nhuman operators, working in two coordinated multi-robot tasks.$\backslash$nIn these, we contrasted standard displays, which assume each$\backslash$nrobot is independent, with an ecological socially-attentive display$\backslash$nthat makes the state of coordination explicit. The results show$\backslash$nsignicant improvements in task completion time, number of$\backslash$nfailures, and the failure rate. Moreover, the display reduces the$\backslash$nvariance in operator control, thus leading to signicantly more$\backslash$nconsistent operator performance.},
author = {Kaminka, Gal A. and Elmaliach, Yehuda},
doi = {10.1109/ROBOT.2006.1641184},
isbn = {0780395069},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {multi-robot,taxonomy},
mendeley-tags = {multi-robot,taxonomy},
number = {May},
pages = {200--205},
title = {{Experiments with an ecological interface for monitoring tightly-coordinated robot teams}},
volume = {2006},
year = {2006}
}
@inproceedings{Scholtz2003,
author = {Scholtz, J.},
booktitle = {36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the},
doi = {10.1109/HICSS.2003.1174284},
isbn = {0-7695-1874-5},
keywords = {adrenoceptors,ductus venosus,glucocorticoids,lactate metabolism,liver glycogen,taxonomy},
mendeley-tags = {taxonomy},
number = {24},
pages = {10 pp.},
pmid = {9355799},
publisher = {IEEE},
title = {{Theory and evaluation of human robot interactions}},
url = {http://ieeexplore.ieee.org/document/1174284/},
volume = {24},
year = {2003}
}
@techreport{Jain,
author = {Jain, Raj},
file = {::},
keywords = {Assistive Robotics,Autonomous Robotics,Benchmarking 1 Introduction 2 Assistive Robotics 2,Human Robot Interaction,Metrics,Modeling,Performance Analysis,Real-time robotic systems,Robotics,Simulation,Unmanned Aerial Vehicle,multi-robot systems,taxonomy},
mendeley-tags = {taxonomy},
title = {{A Survey of Robotics Systems and Performance Analysis}},
url = {http://www1.cse.wustl.edu/{~}jain/cse567-11/ftp/robots/index.html}
}
@techreport{Yanco2002,
abstract = {This paper integrates research and ideas in the fields of Human-Computer Interaction and Robotics for the creation of a taxonomy for human-robot interaction. By drawing from multiple research fields, a more complete taxonomy is attained. Taxonomy categories include team composition (ratio of people to robots, types of robots), amount of required interaction, decision support provided for the user, and space-time location.},
author = {Yanco, Holly A and Drury, Jill L},
file = {::},
keywords = {taxonomy},
mendeley-tags = {taxonomy},
pages = {111--119},
title = {{A Taxonomy for Human-Robot Interaction}},
year = {2002}
}
@inproceedings{Drury2003,
author = {Drury, Jill L and Scholtz, Jean and Yanco, Holly A},
file = {::},
keywords = {taxonomy},
mendeley-tags = {taxonomy},
title = {{Awareness in Human-Robot Interactions}},
url = {http://www.cs.uml.edu/{~}holly/papers/smc2003.pdf},
year = {2003}
}
@inproceedings{Fong2003,
abstract = {This paper reviews "socially interactive robots": robots for which social human-robot interaction is important. We begin by discussing the context for socially interactive robots, emphasizing the relationship to other research fields and the different forms of "social robots". We then present a taxonomy of design methods and system components used to build socially interactive robots. Finally, we describe the impact of these robots on humans and discuss open issues. An expanded version of this paper, which contains a survey and taxonomy of current applications, is available as a technical report [T. Fong, I. Nourbakhsh, K. Dautenhahn, A survey of socially interactive robots: concepts, design and applications, Technical Report No. CMU-RI-TR-02-29, Robotics Institute, Carnegie Mellon University, 2002]. {\textcopyright} 2003 Elsevier Science B.V. All rights reserved.},
archivePrefix = {arXiv},
author = {Fong, Terrence and Nourbakhsh, Illah and Dautenhahn, Kerstin},
booktitle = {Robotics and Autonomous Systems},
doi = {10.1016/S0921-8890(02)00372-X},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {09218890},
issn = {09218890},
keywords = {Human-robot interaction,Interaction aware robot,Sociable robot,Social robot,Socially interactive robot,survey},
mendeley-tags = {survey},
pmid = {15717012},
title = {{A survey of socially interactive robots}},
year = {2003}
}
@article{Argall2009,
abstract = {We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1105.1186v1},
author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
doi = {10.1016/j.robot.2008.10.024},
eprint = {arXiv:1105.1186v1},
file = {::},
isbn = {0921-8890},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Autonomous systems,Learning from demonstration,Machine learning,Robotics,survey},
mendeley-tags = {survey},
pmid = {21045796},
title = {{A survey of robot learning from demonstration}},
year = {2009}
}
@inproceedings{Cakmak2012,
abstract = {Programming new skills on a robot should takeminimal time and effort. One approach to achieve this goal is to allow the robot to ask questions. This idea, called Active Learning, has recently caught a lot of attention in the robotics commu- nity. However, it has not been explored from a human-robot interaction perspective. In this paper, we identify three types of questions (label, demonstration and feature queries) and discuss how a robot can use these while learning new skills. Then, we present an experiment on human question asking which characterizes the extent to which humans use these question types. Finally, we evaluate the three question types within a human-robot teaching interaction. We inves- tigate the ease with which different types of questions are answered and whether or not there is a general preference of one type of question over another. Based on our findings from both experiments we provide guidelines for designing question asking behaviors on a robot learner.},
author = {Cakmak, Maya and Thomaz, Andrea L.},
booktitle = {Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction - HRI '12},
doi = {10.1145/2157689.2157693},
file = {::},
isbn = {9781450310635},
issn = {2167-2121},
title = {{Designing robot learners that ask good questions}},
year = {2012}
}
@article{Cakmak2010,
abstract = {Social learning in robotics has largely focused on imitation learning. Here we take a broader view and are in- terested in the multifaceted ways that a social partner can influence the learning process. We implement four social learning mechanisms on a robot: stimulus enhancement, em- ulation, mimicking, and imitation, and illustrate the compu- tational benefits of each. In particular,we illustrate that some strategies are about directing the attention of the learner to objects and others are about actions. Taken together these strategies form a rich repertoire allowing social learners to use a social partner to greatly impact their learning process. We demonstrate these results in simulation and with physi- cal robot ‘playmates'.},
author = {Cakmak, Maya and Depalma, Nick and Arriaga, Rosa I. and Thomaz, Andrea L.},
doi = {10.1007/s10514-010-9197-9},
file = {::},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {Biologically inspired learning,Learning by imitation,Social learning},
title = {{Exploiting social partners in robot learning}},
year = {2010}
}
@inproceedings{Fong2001,
abstract = {Teleoperation can be significantly improved if humans and robots work as partners. By adapting autonomy and human-robot interaction to the situation and the user, we can create systems which are easier to use and better performing. In this paper, we discuss the importance of collaboration and dialogue in human-robot systems. We then present a system based on collaborative control, a teleoperation model in which humans and robots collaborate to perform tasks. Finally, we describe our experiences using this system for vehicle teleoperation.},
address = {Lorne, Victoria, Australia Collaboration,},
author = {Fong, Terrence and Thorpe, Charles and Baur, Charles},
booktitle = {10th International Symposium of Robotics Research},
doi = {10.1007/3-540-36460-9_17},
file = {::},
isbn = {978-3-540-00550-6},
issn = {1439-4286},
pages = {255--266},
pmid = {21773965},
publisher = {Springer Berlin Heidelberg},
title = {{Collaboration, Dialogue, and Human-Robot Interaction}},
url = {http://link.springer.com/10.1007/3-540-36460-9{\_}17},
year = {2001}
}
@incollection{Mataric2016,
abstract = {The main objective of this dissertation is the implementation of a multi-layered control architecture for the study of HRI in a socially assistive scenario. With this control archi- tecture we intended to endow an anthropomorphic robot with the capability of helping humans with motor impairments in their common daily tasks (e.g. drinking, eating), in a fluent and flexible way. As an important requirement the robot is intended to show some social skills in order to act as a Socially Assistive Robot. The proposed architecture was implemented applying to the neuro-cognitive principles underlying the Mirror Neuron System (MNS) and the concepts related with the Dynamic Neural Fields (DNF). Nowadays, there are solid evidences that attest the presence of the mirror neurons in both human and non-human primates. The mirror neurons are the basic units of the Mirror Neuron System. The MNS is thought to be the fundamental mechanisms for ac- tion representation and understanding within the brain cortical structure (Iacoboni et al., 1999). The ability to understand the actions done by others', as well as their outcomes, are key factors for life in society. Thus, it is thought that the mirror neurons are on the basis of the demonstration of social skills by human and non-human primates. By modeling the basic functioning of the Mirror Neuron System, as well as its functional relationships with other nearby brain areas, we want the robot to be endowed with mechanisms that allows it to show some human-like social skills, such as reading motor intentions, action understanding, anticipation and flexible decision making. Each layer of the proposed architecture is formalized as a Dynamic Neural Field, as proposed in the Dynamic Neural Field Approach to Cognitive Robotics (review e.g. Erlhagen and Bicho (2006)). This approach makes use of the Amari equation (Amari (1977)) that enables the mathematical modeling of the mechanisms underlying pattern formation within the neuronal structures.},
author = {Matari{\'{c}}, Maja J. and Scassellati, Brian},
booktitle = {Springer Handbook of Robotics},
doi = {10.1007/978-3-319-32552-1_73},
file = {::},
isbn = {9780549679042},
issn = {1070-9932},
pmid = {15448124},
title = {{Socially Assistive Robotics}},
year = {2016}
}
@article{Cha2018,
abstract = {The goal of this survey is to inform the design and usage of nonverbal signals for human-robot interaction. With robots being increasingly utilized for tasks that require them to not only operate in close proximity to humans but to interact with them as well, there has been great interest in the communication challenges associated with the varying degrees of interaction in these environments. The success of such interactions depends on robots' ability to convey information about their knowledge, intent, and actions to co-located humans. In this work, we present a comprehensive review of literature related to the generation and usage of nonverbal signals that facilitate legibility of non-humanoid robot state and behavior. To motivate the need for these signaling behaviors, we survey literature in human communication and psychology and outline target use cases of non-humanoid robots. Specifically, we focus on works that provide insight into the cognitive processes that enable humans to recognize, interpret, and exploit nonverbal signals. From these use cases, we identify information that is potentially important for non-humanoid robots to signal and organize it into three categories of robot state. We then present a review of signal design techniques to illustrate how signals conveying this information can be generated and utilized. Finally, we discuss issues that must be considered during nonverbal signaling and open research areas, with a focus on informing the design and usage of generalizable nonverbal signaling behaviors for task-oriented non-humanoid robots.},
author = {Cha, Elizabeth and Kim, Yunkyung and Fong, Terrence and Mataric, Maja J.},
doi = {10.1561/2300000057},
file = {::},
isbn = {9781680834086},
issn = {1935-8253},
journal = {Foundations and Trends in Robotics},
keywords = {survey},
mendeley-tags = {survey},
title = {{A Survey of Nonverbal Signaling Methods for Non-Humanoid Robots}},
year = {2018}
}
@techreport{Mead2014,
author = {Mead, Ross and Atrash, Amin and Kaszubski, Edward and Clair, Aaron St and Greczek, Jillian and Clabaugh, Caitlyn and Kohan, Brian and Matari{\'{c}}, Maja J},
file = {::},
keywords = {AAAI Technical Report FS-14-01},
title = {{Building Blocks of Social Intelligence: Enabling Autonomy for Socially Intelligent and Assistive Robots}},
url = {www.ros.org},
year = {2014}
}
@ARTICLE{Parasuraman2000, 
author={R. Parasuraman and T. B. Sheridan and C. D. Wickens}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans}, 
title={A model for types and levels of human interaction with automation}, 
year={2000}, 
volume={30}, 
number={3}, 
pages={286-297}, 
keywords={man-machine systems;user interfaces;human factors;automation;human computer interaction;automation;information acquisition;information analysis;human factors;man machine systems;function allocation;cognitive engineering;Humans;Design automation;NASA;Hardware;Software;Man machine systems;Costs;Information analysis;Reliability engineering;Design engineering}, 
doi={10.1109/3468.844354}, 
ISSN={1083-4427}, 
month={May},}
@Article{Sheridan2001,
  author    = {Thomas B. Sheridan},
  title     = {Rumination on automation, 1998},
  journal   = {Annual Reviews in Control},
  year      = {2001},
  volume    = {25},
  pages     = {89 - 97},
  month     = {jan},
  issn      = {1367-5788},
  abstract  = {In recent years there has been great interest in the evidence that with experience human decision-making becomes “automatic”, “recognition-primed”, “naturalistic”, “situated”, and “ecological”. Advocates of these approaches have rejected classical decision theory as a description of decision-making in real tasks. This rejection poses a challenge to better understand human automaticity by extending normative decision modeling. Two approaches, both based on state-space reduction, are discussed. There is also the challenge of relating these models to what is being learned in neurobiology, and again a model is presented which potentially explains how behavior can become automatic. Implications for computer-based automation of decision aiding and control are also proposed, including a revised four-stage format for scaling levels of automation.},
  doi       = {10.1016/s1367-5788(01)00009-8},
  keywords  = {Decision, models, memory, criteria, neurobiology, automation, control, safety},
  publisher = {Elsevier {BV}},
  url       = {http://www.sciencedirect.com/science/article/pii/S1367578801000098},
}
@techreport{Sheridan1978,
abstract = {This is a review of factors pertaining to man-machine interaction in remote control of undersea vehicles, especially their manipulators and sensors. Emphasis is placed on human operator control of such teleoperator systems as a function of degree of automation, sensor-control integration and task demands for underwater search, object recovery and manipulation. Models of operator- computer performance are considered, particularly with respect to human supervisory control of semiautonomous systems. Sections of the report discuss: teleoperated submersible vehicles or work platforms; undersea tasks and how they can be analyzed; relative roles of human and computer or other control elements; control hardware (sensors, communication, propulsion, manipulation, control station) and how it affects the human controller; control software for computer- aided manipulation, including a review of various languages and algorithms presently available; human operator performance in manipulator control (a review of what we now know); present and prospective theoretical models of supervisory control; and finally, the needs for research in this area.},
author = {Sheridan, Thomas B. and Verplank, William L.},
booktitle = {J. Vertebr. Paleontol.},
institution = {US Dept of the Navy},
isbn = {0315737948},
issn = {0272-4634},
keywords = {COMPUTERS,CONTROL EQUIPMENT,HUMAN-COMPUTER INTERFACE,MAN MACHINE SYSTEMS,MARINE ENVIRONMENTS,NUMERICAL CONTROL,OCEANS,REMOTE SENSORS,SYSTEMS ENGINEERING,TELEOPERATORS},
month = {jul},
number = {2},
pages = {266--266},
pmid = {5322634},
title = {{Human and Computer Control of Undersea Teleoperators}},
volume = {13},
year = {1978}
}

@article{endsley_level_1999,
	title = {Level of automation effects on performance, situation awareness and workload in a dynamic control task},
	volume = {42},
	issn = {0014-0139},
	doi = {10.1080/001401399185595},
	language = {eng},
	number = {3},
	journal = {Ergonomics},
	author = {Endsley, M. R. and Kaber, D. B.},
	month = mar,
	year = {1999},
	pmid = {10048306},
	keywords = {Adult, Analysis of Variance, Automation, Awareness, Cognition, Equipment Failure, Evaluation Studies as Topic, Female, Humans, Internal-External Control, Male, Task Performance and Analysis, User-Computer Interface, Workload},
	pages = {462--492},
}
@article{thrun_toward_2004,
	title = {Toward a {Framework} for {Human}-robot {Interaction}},
	volume = {19},
	issn = {0737-0024},
	url = {http://dx.doi.org/10.1207/s15327051hci1901&2_2},
	doi = {10.1207/s15327051hci1901&2_2},
	number = {1},
	urldate = {2018-11-07},
	journal = {Hum.-Comput. Interact.},
	author = {Thrun, Sebastian},
	month = jun,
	year = {2004},
	pages = {9--24},
	file = {Thrun - Toward a Framework for Human–Robot Interaction.pdf:C\:\\Users\\pripa\\Zotero\\storage\\JG3SRBCE\\Thrun - Toward a Framework for Human–Robot Interaction.pdf:application/pdf}
}
@article{Ellis1991,
author = {Ellis, Clarence A. and Gibbs, Simon J. and Rein, Gail},
doi = {10.1145/99977.99987},
isbn = {0133051943},
issn = {00010782},
journal = {Commun. ACM},
keywords = {human-computer interaction},
mendeley-tags = {human-computer interaction},
month = {jan},
number = {1},
pages = {39--58},
pmid = {12238525},
title = {{Groupware: some issues and experiences}},
url = {http://portal.acm.org/citation.cfm?doid=99977.99987},
volume = {34},
year = {1991}
}
@inproceedings{Nickerson1997,
author = {Nickerson, Robert C.},
booktitle = {Proc. Am. Conf. Inf. Syst.},
keywords = {human-computer interaction},
mendeley-tags = {human-computer interaction},
title = {{A Taxonomy of Collaborative Applications}},
year = {1997}
}
@article{Brandt2001,
author = {Brandt, Keri},
doi = {10.1163/1568530043068010},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Brandt - 2001 - A Language of Their Own An Interactionist Approach to Human-Horse Communication.pdf:pdf},
issn = {1063-1119},
journal = {Soc. Anim.},
keywords = {horses,human-animal,to-read},
mendeley-tags = {horses,human-animal,to-read},
month = {dec},
number = {4},
pages = {299--316},
publisher = {Wissler},
title = {{A Language of Their Own: An Interactionist Approach to Human-Horse Communication}},
url = {https://www.animalsandsociety.org/wp-content/uploads/2015/11/brandt.pdf https://brill.com/abstract/journals/soan/12/4/article-p299{\_}2.xml},
volume = {12},
year = {2004}
}
@article{Frohoff,
author = {Frohoff, Toni G and Packard, Jane M},
doi = {10.2752/089279395787156527},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Frohoff, Packard - 1995 - Human Interactions with Free-Ranging and Captive Bottlenose Dolphins.pdf:pdf},
issn = {0892-7936},
journal = {Anthrozo\" os},
keywords = {dolphins,human-animal,to-read},
mendeley-tags = {dolphins,human-animal,to-read},
month = {mar},
number = {1},
pages = {44--53},
title = {{Human Interactions with Free-Ranging and Captive Bottlenose Dolphins}},
url = {http://www.tandfonline.com/action/journalInformation?journalCode=rfan20 https://www.tandfonline.com/doi/full/10.2752/089279395787156527},
volume = {8},
year = {1995}
}
@article{Naderi2001,
author = {Naderi, Sz and Mikl{\'{o}}si, {\'{A}} and D{\'{o}}ka, A and Cs{\'{a}}nyi, V},
doi = {10.1016/S0168-1591(01)00152-6},
file = {::},
issn = {01681591},
journal = {Appl. Anim. Behav. Sci.},
keywords = {Co-operation,Dog±human interaction,Guide dogs for the blind,dogs,human-animal},
mendeley-tags = {human-animal,dogs},
month = {sep},
number = {1},
pages = {59--80},
title = {{Co-operative interactions between blind persons and their dogs}},
url = {http://etologia.elte.hu/file/publikaciok/2001/naderiMDCS2001.pdf http://linkinghub.elsevier.com/retrieve/pii/S0168159101001526},
volume = {74},
year = {2001}
}
@article{Phillips2015,
author = {Phillips, Elizabeth Kathleen and Schaefer, Kristin and Billings, Deborah R and Jentsch, Florian and Hancock, Peter A},
doi = {10.5898/JHRI.5.1.Phillips},
file = {::},
issn = {2163-0364},
journal = {J. Human-Robot Interact.},
keywords = {human-animal,survey},
mendeley-tags = {human-animal,survey},
month = {sep},
number = {1},
pages = {100},
title = {{Human-Animal Teams as an Analog for Future Human-Robot Teams: Influencing Design and Fostering Trust}},
url = {http://delivery.acm.org/10.1145/3110000/3109944/p100-phillips.pdf?ip=172.4.35.10{\&}id=3109944{\&}acc=OA{\&}key=4D4702B0C3E38B35.4D4702B0C3E38B35.4D4702B0C3E38B35.6D218144511F3437{\&}{\_}{\_}acm{\_}{\_}=1547870456{\_}7ca7786a0d5fa0a6bea5eb3b8a2a7d24 http://dl.acm.org/citation.cfm?id=3109944},
volume = {5},
year = {2015}
}
@article{Phillips2012,
author = {Phillips, Elizabeth and Ososky, Scott and Swigert, Brittany and Jentsch, Florian},
doi = {10.1177/1071181312561309},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Phillips et al. - 2012 - Human-animal teams as an analog for future human-robot teams.pdf:pdf},
issn = {1541-9312},
journal = {Proc. Hum. Factors Ergon. Soc. Annu. Meet.},
keywords = {human-animal,survey},
mendeley-tags = {human-animal,survey},
month = {sep},
number = {1},
pages = {1553--1557},
title = {{Human-animal teams as an analog for future human-robot teams}},
url = {https://journals.sagepub.com/doi/pdf/10.1177/1071181312561309?casa{\_}token=eytsvtrcZMgAAAAA{\%}3A436rkAIaX3s24d3vjQbrCwJ3fG-T1PRgBMDhEr4CVznsP{\_}9jZTDzf68b3dk8A-Axo86r0kB4Rdg http://journals.sagepub.com/doi/10.1177/1071181312561309},
volume = {56},
year = {2012}
}
@article{Bottlenose1994,
author = {Pryor, Karen and Lindbergh, Jon},
doi = {https://doi.org/10.1111/j.1748-7692.1990.tb00228.x},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Pryor, Lindbergh - 1990 - A DOLPHIN-HUMAN FISHING COOPERATIVE IN BRAZIL.pdf:pdf},
journal = {Mar. Mammal Sci.},
keywords = {dolphins,human-animal},
mendeley-tags = {human-animal,dolphins},
number = {1},
pages = {77--82},
title = {{A DOLPHIN-HUMAN FISHING COOPERATIVE IN BRAZIL}},
volume = {6},
year = {1990}
}
@article{Topal1997,
author = {Top{\'{a}}l, J and Mikl{\'{o}}si, {\'{A}} and Cs{\'{a}}nyi, V},
doi = {10.2752/089279397787000987},
file = {::},
issn = {0892-7936},
journal = {Anthrozo\" ots},
keywords = {dogs,human-animal},
mendeley-tags = {dogs,human-animal},
month = {dec},
number = {4},
pages = {214--224},
title = {{Dog-Human Relationship Affects Problem Solving Behavior in the Dog}},
url = {http://www.tandfonline.com/action/journalInformation?journalCode=rfan20 https://www.tandfonline.com/doi/full/10.2752/089279397787000987},
volume = {10},
year = {1997}
}
@article{Doroodgar2010,
abstract = {Current applications of mobile robots in urban search and rescue (USAR) environments require a human operator in the loop to help guide the robot remotely. Although human operation can be effective, the unknown cluttered nature of the environments make robot navigation and victim identification highly challenging. Operators can become stressed and fatigued very quickly due to a loss of situational awareness, leading to the robots getting stuck and not being able to find victims in the scene during this time-sensitive operation. In addition, current autonomous robots are not capable of traversing these complex unpredictable environments. To address this challenge, a balance between the level of autonomy of the robot and the amount of human control over the robot needs to be addressed. In this paper, we present a unique control architecture for semi-autonomous navigation of a robotic platform utilizing sensory information provided by a novel real-time 3D mapping sensor. The control system provides the robot with the ability to learn and make decisions regarding which rescue tasks should be carried out at a given time and whether an autonomous robot or a human controlled robot can perform these tasks more efficiently without compromising the safety of the victims, rescue workers and the rescue robot. Preliminary experiments were conducted to evaluate the performance of the proposed collaborative control approach for a USAR robot in an unknown cluttered environment.},
author = {Doroodgar, Barzin and Ficocelli, Maurizio and Mobedi, Babak and Nejat, Goldie},
doi = {10.1109/ROBOT.2010.5509530},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Doroodgar et al. - 2010 - The search for survivors Cooperative human-robot interaction in search and rescue environments using semi-auto.pdf:pdf},
isbn = {9781424450381},
issn = {10504729},
journal = {Proc. - IEEE Int. Conf. Robot. Autom.},
keywords = {algorithm,usar},
mendeley-tags = {usar,algorithm},
pages = {2858--2863},
publisher = {IEEE},
title = {{The search for survivors: Cooperative human-robot interaction in search and rescue environments using semi-autonomous robots}},
year = {2010}
}
@article{Baker2004,
abstract = {Studies of human-robot interaction have shown that operators rely heavily upon the video stream, to the exclusion of all other information on the interface. We have created a new interface that fuses information on and around the video window to exploit this fact.},
author = {Baker, Michael and Casey, Robert and Keyes, Brenden and Yanco, Holly A.},
doi = {10.1109/ICSMC.2004.1400783},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Baker et al. - 2004 - Improved interfaces for human-robot interaction in urban search and rescue.pdf:pdf},
isbn = {0780385667},
issn = {1062922X},
journal = {Conf. Proc. - IEEE Int. Conf. Syst. Man Cybern.},
keywords = {Human-robot interaction,Search and rescue,usar,ux},
mendeley-tags = {ux,usar},
pages = {2960--2965},
pmid = {359950},
title = {{Improved interfaces for human-robot interaction in urban search and rescue}},
volume = {3},
year = {2004}
}
@inproceedings{Kruijff2012,
author = {Kruijff, Geert and Jan{\'{i}}cek, Miroslav and Keshavdas, Shanker and Larochelle, Benoit and Zender, Hendrik and Smets, Nanja and Mioch, Tina and Neerincx, Mark and Van, Jurriaan},
booktitle = {8th Int. Conf. F. Serv. Robot.},
file = {::},
keywords = {higher-autonomy,lessons,usar},
mendeley-tags = {higher-autonomy,lessons,usar},
title = {{Experience in System Design for Human-Robot Teaming in Urban Search}},
url = {https://hal.archives-ouvertes.fr/hal-01143147},
year = {2012}
}
@article{Scholtz2004SaR,
author = {Scholtz, J. and Young, J. and Drury, J.L. and Yanco, H.A.},
doi = {10.1109/ROBOT.2004.1307409},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Scholtz et al. - 2004 - Evaluation of human-robot interaction awareness in search and rescue.pdf:pdf},
isbn = {0-7803-8232-3},
issn = {1050-4729},
journal = {IEEE Int. Conf. Robot. Autom. 2004. Proceedings. ICRA '04. 2004},
keywords = {-human-robot inferaction,according,completely autonomous robots for,feasible in the near,future,operators must work as,teammates,urban search and rescue,usar,usar are definitely not,ux,with all parties contributing,with the usar robots},
mendeley-tags = {usar,ux},
pages = {2327--2332 Vol.3},
title = {{Evaluation of human-robot interaction awareness in search and rescue}},
url = {http://ieeexplore.ieee.org/document/1307409/},
year = {2004}
}
@article{Hong2018,
abstract = {Teams of semi-autonomous robots can provide valuable assistance in Urban Search and Rescue (USAR) by efficiently exploring cluttered environments and searching for potential victims. Their advantage over solely teleoperated robots is that they can address the task handling and situation awareness limitations of human operators by providing some level of autonomy to the multi-robot team. Our research focuses on developing learning-based semi-autonomous controllers for rescue robot teams. In this paper, we specifically investigate the influence of the operator-to-robot ratio on the performance of our proposed MAXQ hierarchical reinforcement learning based semi-autonomous controller for USAR missions. In particular, we propose a unique learning-based system architecture that allows operator control of larger numbers of rescue robots in a team as well as effective sharing of information between these robots. A rigorous comparative study of our learning-based semi-autonomous controller versus a fully teleoperation-based approach was conducted in a 3D simulation environment. The results, as expected, show that, for both semi-autonomous and teleoperation modes, the total scene exploration time increases as the number of robots utilized increases. However, when using the proposed learning-based semi-autonomous controller, the rate of exploration-time increase and operator-interaction effort are significantly lower, while task performance is significantly higher. Furthermore, an additional case study showed that our learning-based approach can provide more scene coverage during robot exploration when compared to a non-learning based method.},
author = {Hong, A and Igharoro, {\textperiodcentered} O and Liu, {\textperiodcentered} Y and Niroui, {\textperiodcentered} F and Nejat, {\textperiodcentered} G and Benhabib, {\textperiodcentered} B},
doi = {10.1007/s10846-018-0899-0},
file = {::},
keywords = {learning,sliding-autonomy,usar},
mendeley-tags = {learning,sliding-autonomy,usar},
title = {{Investigating Human-Robot Teams for Learning-Based Semi-autonomous Control in Urban Search and Rescue Environments}},
url = {https://doi.org/10.1007/s10846-018-0899-0}
}
@techreport{Bruemmer2002,
abstract = {At the 2002 AAAI Robotics Competition and Exhibition, the Idaho National Engineering and Environmental Laboratory (INEEL) demonstrated a robot that can adjust its l evel of autonomy on the fly, leveraging its own, intrinsic intelligence to meet whatever level of control was handed down from the user. The robot had the ability to actively protect itself and the environment as it navigated through the USAR environment. In addition, the robot continuously assessed and adapted to changes in its own perceptual capabilities. The INEEL also demonstrated an interface for supporting mixed-initiative interaction between the operator and human. The interface displays an abstracted representation of the robot's experience and exploits sensor-suites and fusion algorithms that enhance capabilities for sensing, interpreting, and "understanding" environmental features. This paper reports on the current robotic system including hardware, sensor suite, control architecture, and interface system.},
author = {Bruemmer, David J and Dudenhoeffer, Donald D and Marble, Julie L},
file = {::},
keywords = {autonomy,usar},
mendeley-tags = {autonomy,usar},
title = {{Dynamic-Autonomy for Urban Search and Rescue}},
url = {www.aaai.org},
year = {2002}
}
@article{Burke2004Miami,
author = {Burke, Jennifer L and Murphy, Robin R and Coovert, Michael D and Riddle, Dawn L},
doi = {10.1080/07370024.2004.9667341},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Burke et al. - 2004 - Moonlight in Miami Field Study of Human-Robot Interaction in the Context of an Urban Search and Rescue Disaster Re.pdf:pdf},
keywords = {miami,usar},
mendeley-tags = {miami,usar},
pages = {85--116},
title = {{Moonlight in Miami: Field Study of Human-Robot Interaction in the Context of an Urban Search and Rescue Disaster Response Training Exercise Moonlight in Miami: A Field Study of Human-Robot Interaction in the Context of an Urban Search and Rescue Disaster Response Training Exercise}},
url = {https://doi.org/10.1080/07370024.2004.9667341},
volume = {19},
year = {2004}
}
@article{Karma2015,
abstract = {Search and Rescue (SaR) in forest fires is usually applied in a broad area, under foggy or smoky conditions. It mostly involves location of entrapped fire crew or people in between fire fronts, as well as, safely removing them away from the dangerous zone. Moreover, SaR is applied in evacuation of rural residential areas due to heavy smoke impacts, or fire front approaching. Experiences achieved during a field trial, in which unmanned aerial and ground vehicles were deployed and used in a simulated forest fire SaR scenario, are presented. For planning and running the field trial a number of parameters were taken into consideration; logistics, safety plan, contingency plan, different agencies cooperation, time frames and ethical issues. Advantages of using unmanned aerial and ground vehicles in SaR operations include capability of planning and monitoring the operations, integration with the manned resources, connectivity with command and control centers, as well as, coordination of the different unmanned aerial and ground vehicles' platforms. Significant increase of personnel safety is possible through the capabilities of air quality monitoring and search over dangerous areas. Current limitations include limited heat resistance of vehicles and limited flying capability in strong winds and turbulence. Failure of communications is also possible due to rough terrain (autonomy limitations). Against all the limitations, a number of unmanned vehicles already exist that can be adapted successfully for SaR operations in forest fires.},
author = {Karma, S. and Zorba, E. and Pallis, G.C. and Statheropoulos, G. and Balta, I. and Mikedi, K. and Vamvakari, J. and Pappa, A. and Chalaris, M. and Xanthopoulos, G. and Statheropoulos, M.},
doi = {10.1016/J.IJDRR.2015.07.009},
file = {::},
journal = {Int. J. Disaster Risk Reduct.},
keywords = {forest-fire,usar},
mendeley-tags = {forest-fire,usar},
month = {sep},
pages = {307--312},
publisher = {Elsevier},
title = {{Use of unmanned vehicles in search and rescue operations in forest fires: Advantages and limitations observed in a field trial}},
url = {https://www.sciencedirect.com/science/article/pii/S2212420915300364},
volume = {13},
year = {2015}
}
@article{Casper2003,
abstract = {The World Trade Center (WTC) rescue response provided an unfortunate opportunity to study the human-robot interactions (HRI) during a real unstaged rescue for the first time. A post-hoc analysis was performed on the data collected during the response, which resulted in 17 findings on the impact of the environment and conditions on the HRI: the skills displayed and needed by robots and humans, the details of the Urban Search and Rescue (USAR) task, the social informatics in the USAR domain, and what information is communicated at what time. The results of this work impact the field of robotics by providing a case study for HRI in USAR drawn from an unstaged USAR effort. Eleven recommendations are made based on the findings that impact the robotics, computer science, engineering, psychology, and rescue fields. These recommendations call for group organization and user confidence studies, more research into perceptual and assistive interfaces, and formal models of the state of the robot, state of the world, and information as to what has been observed.},
author = {Casper, Jennifer and Murphy, Robin Roberson},
doi = {10.1109/TSMCB.2003.811794},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Casper, Murphy - 2003 - Human-robot interactions during the robot-assisted urban search and rescue response at the World Trade Center.pdf:pdf},
isbn = {9780470132531},
issn = {10834419},
journal = {IEEE Trans. Syst. Man, Cybern. Part B Cybern.},
keywords = {Human-robot interaction,Urban search and rescue,World Trade Center (WTC),case-study,usar},
mendeley-tags = {case-study,usar},
number = {3},
pages = {367--385},
pmid = {18238185},
publisher = {IEEE},
title = {{Human-robot interactions during the robot-assisted urban search and rescue response at the World Trade Center}},
volume = {33},
year = {2003}
}
@article{Nourbakhsh2005,
abstract = {This work establishes an architecture for Urban Search and Rescue and a methodology for mixing real-world and simulation-based testing. A sensor suite and sensor fusion algorithm for robust victim detection permits aggregation of sensor readings from various sensors on multiple robots. We have embarked on a research program focusing on the enabling technologies of effective USAR robotic rescue devices. The program is also researching system-level design, evaluation, and refinement of USAR rescue architectures that include teams of sensor-laden robots and human rescuers. In this paper, we present highlights from our research, which include our multiagent system (MAS) infrastructure, our simulation environment, and our approach to sensor fusion and interface design for effective robotic control.},
author = {Nourbakhsh, Illah R. and Sycara, Katia and Koes, Mary and Yong, Mark and Lewis, Michael and Burion, Steve},
doi = {10.1109/MPRV.2005.13},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Nourbakhsh et al. - 2005 - Human-robot teaming for Search and Rescue.pdf:pdf},
isbn = {1536-1268},
issn = {15361268},
journal = {IEEE Pervasive Comput.},
keywords = {architecture,usar,use-case},
mendeley-tags = {architecture,usar,use-case},
number = {1},
pages = {72--77},
title = {{Human-robot teaming for Search and Rescue}},
volume = {4},
year = {2005}
}
@book{suchman1987plans,
  title={Plans and situated actions: The problem of human-machine communication},
  author={Suchman, Lucy A},
  year={1987},
  publisher={Cambridge university press}
}
@misc{Rogers2001,
author = {Rogers, Erika},
booktitle = {Berksh. Encycl. HUMAN-COMPUTER Interact.},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Rogers - 2001 - Human-Robot Interaction.pdf:pdf},
keywords = {introduction,seminal,survey},
mendeley-tags = {introduction,seminal,survey},
title = {{Human-Robot Interaction}},
url = {https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?referer=https://scholar.google.ch/{\&}httpsredir=1{\&}article=1162{\&}context=csse{\_}fac},
year = {2001}
}
@incollection{whitcomb1998towards,
  title={Towards precision robotic maneuvering, survey, and manipulation in unstructured undersea environments},
  author={Whitcomb, Louis and Yoerger, Dana and Singh, Hanumant and Mindell, David},
  booktitle={Robotics Research},
  pages={45--54},
  year={1998},
  publisher={Springer}
}
@article{Thrun1999Minerva,
author = {Thrun, S and Bennewitz, M and Burgard, W and Cremers, A B and Dellaert, F and Fox, D and H{\"{a}}hnel, D and Rosenberg, C and Roy, N and Schulte, J and Schulz, D},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Thrun et al. - 1999 - MINERVA a second-generation museum tour-guide robot.pdf:pdf},
journal = {Proc. 1999 IEEE Int. Conf. Robot. Autom.},
keywords = {docent,seminal},
mendeley-tags = {docent,seminal},
number = {May},
pages = {1999--2005},
title = {{MINERVA: a second-generation museum tour-guide robot}},
year = {1999}
}
@techreport{Burgard1999Mesuem,
author = {Burgard, Wolfram and Cremers, Armin B and Fox, Dieter and H{\"{a}}hnel, Dirk and Lakemeyer, Gerhard and Schulz, Dirk and Steiner, Walter and Thrun, Sebastian},
booktitle = {Artif. Intell.},
file = {::},
keywords = {docent,seminal},
mendeley-tags = {docent,seminal},
pages = {3--55},
title = {{Experiences with an interactive museum tour-guide robot}},
volume = {114},
year = {1999}
}
@inproceedings{pacchierotti2006design,
  title={Design of an office-guide robot for social interaction studies},
  author={Pacchierotti, Elena and Christensen, Henrik I and Jensfelt, Patric},
  booktitle={Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on},
  pages={4965--4970},
  year={2006},
  organization={IEEE}
}
@inproceedings{rosenthal2010effective,
  title={An effective personal mobile robot agent through symbiotic human-robot interaction},
  author={Rosenthal, Stephanie and Biswas, Joydeep and Veloso, Manuela},
  booktitle={Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1},
  pages={915--922},
  year={2010},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
@inproceedings{calinon2007active,
  title={Active teaching in robot programming by demonstration},
  author={Calinon, Sylvain and Billard, Aude},
  booktitle={Robot and Human interactive Communication, 2007. RO-MAN 2007. The 16th IEEE International Symposium on},
  pages={702--707},
  year={2007},
  organization={IEEE}
}
@inproceedings{saunders2006teaching,
  title={Teaching robots by moulding behavior and scaffolding the environment},
  author={Saunders, Joe and Nehaniv, Chrystopher L and Dautenhahn, Kerstin},
  booktitle={Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction},
  pages={118--125},
  year={2006},
  organization={ACM}
}
@book{jentsch2016human,
  title={Human-robot interactions in future military operations},
  author={Jentsch, Florian},
  year={2016},
  publisher={CRC Press}
}
@article{chen2018situation,
  title={Situation awareness-based agent transparency and human-autonomy teaming effectiveness},
  author={Chen, Jessie YC and Lakhmani, Shan G and Stowers, Kimberly and Selkowitz, Anthony R and Wright, Julia L and Barnes, Michael},
  journal={Theoretical issues in ergonomics science},
  volume={19},
  number={3},
  pages={259--282},
  year={2018},
  publisher={Taylor \& Francis}
}
@techreport{Billings2012,
author = {Billings, Deborah R and Schaefer, Kristin E and Chen, Jessie Y C and Kocsis, Vivien and Barrera, Maria and Cook, Jacquelyn and Ferrer, Michelle and Hancock, Peter A},
keywords = {human-animal,human-robot,trust},
mendeley-tags = {human-animal,human-robot,trust},
title = {{Human-Animal Trust as an Analog for Human-Robot Trust: A Review of Current Evidence}},
year = {2012}
}
@article{murphy2000introduction,
  title={Introduction to AI Robotics},
  author={Murphy, Robin R},
  year={2000},
  publisher={MIT Press}
}
@inproceedings{JiangArkin2015,
author = {Jiang, Shu and Arkin, Ronald C},
booktitle = {2015 IEEE Int. Conf. Syst. Man, Cybern.},
doi = {10.1109/SMC.2015.174},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Jiang, Arkin - 2015 - Mixed-Initiative Human-Robot Interaction Definition, Taxonomy, and Survey.pdf:pdf},
isbn = {978-1-4799-8697-2},
keywords = {collective,human-robot interaction,human-robot team,levels of robot autonomy,mixed-initiative interaction,survey,taxonomy},
mendeley-tags = {collective,levels of robot autonomy,taxonomy},
month = {oct},
pages = {954--961},
publisher = {IEEE},
title = {{Mixed-Initiative Human-Robot Interaction: Definition, Taxonomy, and Survey}},
url = {http://www.dtic.mil/dtic/tr/fulltext/u2/a620347.pdf http://ieeexplore.ieee.org/document/7379306/ http://www.dtic.mil/dtic/tr/fulltext/u2/a620347.pdf http://ieeexplore.ieee.org/document/7379306/},
year = {2015}
}
@book{Norman1986,
 author = {Norman, Donald A. and Draper, Stephen W.},
 title = {User Centered System Design; New Perspectives on Human-Computer Interaction},
 year = {1986},
 isbn = {0898597811},
 publisher = {L. Erlbaum Associates Inc.},
 address = {Hillsdale, NJ, USA},
} 
@article{GerkeyMataric2004,
abstract = {Despite more than a decade of experimental work in multi-robot systems, important theoretical aspects of multi-robot coordination mechanisms have, to date, been largely untreated. To address this issue, we focus on the problem of multi-robot task allocation (MRTA). Most work on MRTA has been ad hoc and empirical, with many coordination architectures having been proposed and validated in a proof-of-concept fashion, but infrequently analyzed. With the goal of bringing objective grounding to this important area of research, we present a formal study of MRTA problems. A domain-independent taxonomy of MRTA problems is given, and it is shown how many such problems can be viewed as instances of other, well-studied, optimization problems. We demonstrate how relevant theory from operations research and combinatorial optimization can be used for analysis and greater understanding of existing approaches to task allocation, and to show how the same theory can be used in the synthesis of new approaches.},
author = {Gerkey, Brian P. and Matari{\'{c}}, Maja J.},
doi = {10.1177/0278364904045564},
file = {::},
isbn = {0278-3649},
issn = {02783649},
journal = {Int. J. Rob. Res.},
keywords = {Coordination,Multi-robot systems,Task allocation,Utility,task-allocation,taxonomy},
mendeley-tags = {task-allocation,taxonomy},
number = {9},
pages = {939--954},
pmid = {13688984},
title = {{A formal analysis and taxonomy of task allocation in multi-robot systems}},
url = {https://journals.sagepub.com/doi/pdf/10.1177/0278364904045564?casa{\_}token=1i{\_}Ow{\_}CRetcAAAAA:DVBzk4L3rRNdnQnbZT9wCYLcLdIliEL5nM3Ito9LldAMFExvWUXZ-lWkpBRECpVj{\_}0ASVh3aLVY},
volume = {23},
year = {2004}
}
@article{Korsah2013,
abstract = {Task allocation is an important aspect of many multi-robot systems. The features and complexity of multi-robot task allocation (MRTA) problems are dictated by the requirements of the particular domain under consideration. These problems can range from those involving instantaneous distribution of simple, independent tasks among members of a homogenous team, to those requiring the time-extended scheduling of complex interrelated multi-step tasks for a members of a heterogenous team related by several constraints. The existing widely-used tax-onomy for task allocation in multi-robot systems addresses only problems with independent tasks and does not deal with problems with interrelated utilities and constraints. A survey of recent work in multi-robot task allocation reveals that this is a significant deficiency with respect to realistic multi-robot task allocation problems. Thus, in this paper, we present a new, comprehensive taxonomy, iTax, that explicitly takes into consideration the issues of interrelated utilities and constraints. Our taxonomy maps categories of MRTA problems to existing mathematical models from combinatorial optimization and operations research, and hence draws important parallels between robotics and these fields.},
author = {Korsah, G Ayorkor and Stentz, Anthony and Dias, M Bernardine},
doi = {10.1177/0278364913496484},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Korsah, Stentz, Dias - 2013 - A comprehensive taxonomy for multi-robot task allocation.pdf:pdf},
issn = {0278-3649},
journal = {Int. J. Rob. Res.},
keywords = {task-allocation,task-dependency,taxonomy},
mendeley-tags = {task-allocation,task-dependency,taxonomy},
month = {oct},
number = {12},
pages = {1495--1512},
title = {{A comprehensive taxonomy for multi-robot task allocation}},
url = {http://www.cs.cmu.edu/afs/cs/Web/People/gertrude/documents/Korsah{\_}IJRR{\_}Taxonomy.pdf http://journals.sagepub.com/doi/10.1177/0278364913496484},
volume = {32},
year = {2013}
}
@techreport{ChuinLau2003,
abstract = {Coalition formation has become a key topic in multiagent research. In this paper, we propose a preliminary classification for the coalition formation problem based on three driving factors (demands, resources and profit objectives). We divide our analysis into 5 cases. For each case, we present algorithms and complexity results. We anticipate that with future research, this classification can be extended in similar fashion to the comprehensive classification for the job scheduling problem.},
author = {{Hoong Chuin Lau} and {Lei Zhang}},
booktitle = {Proceedings. 15th IEEE Int. Conf. Tools with Artif. Intell.},
doi = {10.1109/TAI.2003.1250210},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Hoong Chuin Lau, Lei Zhang - 2003 - Task allocation via multi-agent coalition formation taxonomy, algorithms and complexity.pdf:pdf},
isbn = {0-7695-2038-3},
issn = {1082-3409},
keywords = {collective-formation,task-allocation,taxonomy},
mendeley-tags = {collective-formation,task-allocation,taxonomy},
pages = {346--350},
title = {{Task allocation via multi-agent coalition formation: taxonomy, algorithms and complexity}},
url = {http://ieeexplore.ieee.org/document/1250210/},
year = {2003}
}
@article{chandrasekaran1999ontologies,
  title={What are ontologies, and why do we need them?},
  author={Chandrasekaran, Balakrishnan and Josephson, John R and Benjamins, V Richard},
  journal={IEEE Intelligent Systems and their applications},
  volume={14},
  number={1},
  pages={20--26},
  year={1999},
  publisher={IEEE}
}
@article{Miller1967,
author = {Miller, R. B.},
doi = {10.1080/00140136708930856},
issn = {13665847},
journal = {Ergonomics},
keywords = {design,methodology},
mendeley-tags = {design,methodology},
number = {2},
pages = {167--176},
title = {{Task taxonomy: Science or technology?}},
url = {http://www.tandfonline.com/action/journalInformation?journalCode=terg20},
volume = {10},
year = {1967}
}
@article{Mathieu2000TheIO,
author = {Mathieu, John and {S. Heffner}, Tonia and Goodwin, Gerald and Salas, Eduardo and Cannon-Bowers, Janis},
doi = {10.1037/0021-9010.85.2.273},
journal = {Journal of Applied Psychology},
pages = {273--283},
title = {{The Influence of Shared Mental Models on Team Process and Performance}},
volume = {85},
year = {2000}
}
@article{cao1997cooperative,
  title={Cooperative mobile robotics: Antecedents and directions},
  author={Cao, Y Uny and Fukunaga, Alex S and Kahng, Andrew},
  journal={Autonomous robots},
  volume={4},
  number={1},
  pages={7--27},
  year={1997},
  publisher={Springer}
}
@article{Kolling2016,
author = {Kolling, Andreas and Walker, Phillip and Chakraborty, Nilanjan and Sycara, Katia and Lewis, Michael},
doi = {10.1109/THMS.2015.2480801},
journal = {IEEE Transactions on Human-Machine Systems},
keywords = {human-robot,swarm},
mendeley-tags = {human-robot,swarm},
month = {feb},
number = {1},
pages = {9--26},
title = {{Human Interaction With Robot Swarms: A Survey}},
url = {http://ieeexplore.ieee.org/document/7299280/},
volume = {46},
year = {2016}
}
@techreport{Sahin2005,
abstract = {Swarm robotics is a novel approach to the coordination of large numbers of relatively simple robots which takes its inspiration from social insects. This paper proposes a definition to this newly emerging approach by 1) describing the desirable properties of swarm robotic systems, as observed in the system-level functioning of social insects, 2) proposing a definition for the term swarm robotics, and putting forward a set of criteria that can be used to distinguish swarm robotics research from other multi-robot studies, 3) providing a review of some studies which can act as sources of inspiration, and a list of promising domains for the utilization of swarm robotic systems.},
archivePrefix = {arXiv},
author = {\c Sahin, Erol},
file = {::},
isbn = {978-3-540-24296-3},
issn = {0302-9743},
keywords = {applications,swarm},
mendeley-tags = {applications,swarm},
pages = {10--20},
pmid = {16313059},
title = {{Swarm Robotics: From Sources of Inspiration to Domains of Application}},
year = {2005}
}
@inproceedings{Gancet2010,
abstract = {There are many different forms of human-robot interactions, allowing a team of humans and robots to take advantage of skills of each team member. A developing area of research is focused upon the potential of robot swarms working in emergency settings. In particular we consider a swarm of robots that are capable of supporting and enhancing fire fighting operations co-operatively. This paper outlines some of the key characteristics of this emergency setting, robot swarms within it and the work conducted to develop effective human-robot interaction.},
author = {Gancet, Jeremi and Motard, Elvina and Naghsh, Amir and Roast, Chris and Arancon, Miguel Munoz and Marques, Lino},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509890},
file = {::},
isbn = {9781424450381},
issn = {10504729},
keywords = {fire,swarm},
mendeley-tags = {fire,swarm},
pages = {2846--2851},
title = {{User interfaces for human robot interactions with a swarm of robots in support to firefighters}},
url = {https://ieeexplore.ieee.org/ielx5/5501116/5509124/05509890.pdf?tp={\&}arnumber=5509890{\&}isnumber=5509124},
year = {2010}
}
@article{Endsley1995,
author = {Endsley, Mica R.},
doi = {10.1518/001872095779049543},
file = {:home/zephire/Documents/SortedCRITheses/1995/Endsley - Toward a Theory of Situation Awareness in Dynamic Systems.pdf:pdf},
isbn = {0018-7208},
issn = {0018-7208},
journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
keywords = {situational awareness,taxonomy,teams},
mendeley-tags = {situational awareness,taxonomy,teams},
number = {1},
pages = {32--64},
pmid = {17872469},
title = {{Toward a Theory of Situation Awareness in Dynamic Systems}},
url = {http://journals.sagepub.com/doi/10.1518/001872095779049543},
volume = {37},
year = {1995}
}
@inproceedings{endsley1988design,
  title={Design and evaluation for situation awareness enhancement},
  author={Endsley, Mica R},
  booktitle={Proceedings of the Human Factors Society annual meeting},
  volume={32},
  number={2},
  pages={97--101},
  year={1988},
  organization={SAGE Publications Sage CA: Los Angeles, CA}
}
@inproceedings{Feil-Seifer,
author = {Feil-Seifer, David and Mataric, M.J.},
booktitle = {9th International Conference on Rehabilitation Robotics, 2005. ICORR 2005.},
doi = {10.1109/ICORR.2005.1501143},
file = {:home/zephire/Documents/SortedCRITheses/Unknown/Feil-Seifer, Mataric - Defining Socially Assistive Robotics.pdf:pdf},
isbn = {0-7803-9003-2},
keywords = {assistant,social,taxonomy},
mendeley-tags = {assistant,social,taxonomy},
pages = {465--468},
publisher = {IEEE},
title = {{Defining Socially Assistive Robotics}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3287{\&}rep=rep1{\&}type=pdf http://ieeexplore.ieee.org/document/1501143/}
}
@inproceedings{dudek2007visual,
  title={A visual language for robot control and programming: A human-interface study},
  author={Dudek, Gregory and Sattar, Junaed and Xu, Anqi},
  booktitle={Robotics and Automation, 2007 IEEE International Conference on},
  pages={2507--2513},
  year={2007},
  organization={IEEE}
}
@article{kanda2004interactive,
  title={Interactive robots as social partners and peer tutors for children: A field trial},
  author={Kanda, Takayuki and Hirano, Takayuki and Eaton, Daniel and Ishiguro, Hiroshi},
  journal={Human--Computer Interaction},
  volume={19},
  number={1-2},
  pages={61--84},
  year={2004},
  publisher={Taylor \& Francis}
}
@inproceedings{GuoSharlin,
 author = {Guo, Cheng and Sharlin, Ehud},
 title = {Exploring the Use of Tangible User Interfaces for Human-robot Interaction: A Comparative Study},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '08},
 year = {2008},
 isbn = {978-1-60558-011-1},
 location = {Florence, Italy},
 pages = {121--130},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1357054.1357076},
 doi = {10.1145/1357054.1357076},
 acmid = {1357076},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gesture input, human-robot interaction, tangible user interface},
}
@article{Nagi2014,
abstract = {This paper presents a machine vision based approach for human operators to select individual and groups of autonomous robots from a swarm of UAVs. The angular distance between the robots and the human is estimated using measures of the detected human face, which aids to determine human and multi-UAV localization and positioning. In turn, this is exploited to effectively and naturally make the human select the spatially situated robots. Spatial gestures for selecting robots are presented by the human operator using tangible input devices (i.e., colored gloves). To select individuals and groups of robot we formulate a vocabulary of two-handed spatial pointing gestures. With the use of a Support Vector Machine (SVM) trained in a cascaded multi-binary-class configuration, the spatial gestures are effectively learned and recognized by a swarm of UAVs.},
author = {Nagi, Jawad and Giusti, Alessandro and Gambardella, Luca M. and {Di Caro}, Gianni A.},
doi = {10.1109/IROS.2014.6943101},
file = {::},
isbn = {9781479969340},
issn = {21530866},
journal = {IEEE Int. Conf. Intell. Robot. Syst.},
keywords = {gestures,swarm},
mendeley-tags = {gestures,swarm},
number = {Iros},
pages = {3834--3841},
title = {{Human-swarm interaction using spatial gestures}},
year = {2014}
}
@techreport{Suresh2016,
abstract = {We propose a novel Human-Swarm Interaction (HSI) framework which enables the user to control a swarm shape and formation. The user commands the swarm utilizing just arm gestures and motions which are recorded by an off-the-shelf wearable armband. We propose a novel interpreter system, which acts as an intermediary between the user and the swarm to simplify the user's role in the interaction. The interpreter takes in a high level input drawn using gestures by the user, and translates it into low level swarm control commands. This interpreter employs machine learning, Kalman filtering and optimal control techniques to translate the user input into swarm control parameters. A notion of Human Interpretable dynamics is introduced, which is used by the interpreter for planning as well as to provide feedback to the user. The dynamics of the swarm are controlled using a novel decentralized formation controller based on distributed linear iterations and dynamic average consensus. The framework is demonstrated theoretically as well as experimentally in a 2D environment, with a human controlling a swarm of simulated robots in real time.},
archivePrefix = {arXiv},
arxivId = {1804.08676},
author = {Suresh, Aamodh and Martinez, Sonia},
eprint = {1804.08676},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Suresh, Martinez - 2018 - Gesture based Human-Swarm Interactions for Formation Control using interpreters.pdf:pdf},
keywords = {control,distributed control,dynamic average consensus,formation,gesture decoding,gestures,hidden markov models,human interpretable dynamics,human-swarm interaction,kalman filter,swarm},
mendeley-tags = {gestures,swarm},
month = {apr},
title = {{Gesture based Human-Swarm Interactions for Formation Control using interpreters}},
url = {http://arxiv.org/abs/1804.08676},
year = {2018}
}
@article{Alonso-Mora2015,
abstract = {A taxonomy for gesture-based interaction between a human and a group (swarm) of robots is described. Methods are classified into two categories. First, free-form interaction, where the robots are unconstrained in position and motion and the user can use deictic gestures to select subsets of robots and assign target goals and trajectories. Second, shape-constrained interaction, where the robots are in a configuration shape that can be modified by the user. In the later, the user controls a subset of meaningful degrees of freedom defining the overall shape instead of each robot directly. A multi-robot interactive display is described where a depth sensor is used to recognize human gesture, determining the commands sent to a group comprising tens of robots. Experimental results with a preliminary user study show the usability of the system.},
author = {Alonso-Mora, J. and {Haegeli Lohaus}, S. and Leemann, P. and Siegwart, R. and Beardsley, P.},
doi = {10.1109/ICRA.2015.7140033},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Alonso-Mora et al. - 2015 - Gesture based human - Multi-robot swarm interaction and its application to an interactive display.pdf:pdf},
isbn = {978-1-4799-6923-4},
issn = {10504729},
journal = {Proc. - IEEE Int. Conf. Robot. Autom.},
keywords = {gestures,swarm,taxonomy},
mendeley-tags = {gestures,swarm,taxonomy},
number = {June},
pages = {5948--5953},
publisher = {IEEE},
title = {{Gesture based human - Multi-robot swarm interaction and its application to an interactive display}},
volume = {2015-June},
year = {2015}
}
@article{Nagavalli2017,
abstract = {—The theory and design of effective interfaces for human interaction with multi-robot systems has recently gained signifi-cant interest. Robotic swarms are multi-robot systems where local interactions between robots and neighbors within their spatial neighborhood generate emergent collective behaviors. Most prior work has studied interfaces for human interaction with remote swarms, but swarms also have great potential in applications working alongside humans, motivating the need for interfaces for local interaction. Given the collective nature of swarms, human interaction may occur at many levels of abstraction ranging from swarm behavior selection to teleoperation. Wear-able gesture control is an intuitive interaction modality that can meet this requirement while keeping operator hands usually unencumbered. In this paper, we present an interaction method using a gesture-based wearable device with a limited number of gestures for robust control of a complex system: a robotic swarm. Experiments conducted with a real robot swarm compare performance in single and two-operator conditions illustrating the effectiveness of the method. Results show human operators using our interaction method are able to successfully complete the task in all trials, illustrating the effectiveness of the method, with better performance in the two-operator condition, indicating separation of function is beneficial for our method. The primary contribution of our work is the development and demonstration of interaction methods that allow robust control of a difficult to understand multi-robot system using only the noisy inputs typical of smartphones and other on-body sensor driven devices.},
author = {Nagavalli, Sasanka and Chandarana, Meghan and Sycara, Katia and Lewis, Michael},
file = {::},
isbn = {9781612085388},
keywords = {gesture control,gestures,law that allows interactions,local interactions between individual,munication and sensing neighbours,neighbors,only with the robot,robotic swarms,robots and their com-,swarm,wearable devices,within a robotic swarm},
mendeley-tags = {gestures,swarm},
number = {c},
pages = {25--33},
title = {{Multi-Operator Gesture Control of Robotic Swarms Using Wearable Devices}},
year = {2017}
}
@article{Podevijn2014,
abstract = {The term human-swarm interaction (HSI) refers to the interaction be- tween a human operator and a swarm of robots. In this paper, we investigate HSI in the context of a resource allocation and guidance scenario. We present a framework that enables direct communication between human beings and real robot swarms, without relying on a secondary display.We provide the user with a gesture-based interface that allows him to issue commands to the robots. In addi- tion, we develop algorithms that allow robots receiving the commands to display appropriate feedback to the user. We evaluate our framework both in simulation and with real-world experiments.We conduct a summative usability study based on experiments in which participants must guide multiple subswarms to different task locations. 1},
author = {Podevijn, Ga{\"{e}}tan and O'Grady, Rehan and Nashed, Youssef S.G. and Dorigo, Marco},
doi = {10.1007/978-3-662-43645-5_41},
file = {::},
isbn = {9783662436448},
issn = {16113349},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
keywords = {gestures,swarm},
mendeley-tags = {gestures,swarm},
number = {June},
pages = {390--403},
title = {{Gesturing at subswarms: Towards direct human control of robot swarms}},
volume = {8069 LNAI},
year = {2014}
}
@inproceedings{Althaus,
abstract = {One major design goal in human-robot interaction is that the robots behave in an intelligent manner, preferably in a similar way as humans. This constraint must also be taken into consideration when the navigation system for the platform is developed. However, research in human-robot interaction is often restricted to other components of the system including gestures, manipulation, and speech. On the other hand, research for mobile robot navigation focuses primarily on the task of reaching a certain goal point in an environment. We believe that these two problems can not be treated separately for a personal robot that coexists with humans in the same surrounding. Persons move constantly while they are interacting with each other. Hence, also a robot should do that, which poses constraints on the navigation system. This type of navigation is the focus of this paper. Methods have been developed for a robot to join a group of people engaged in a conversation. Preliminary results show that the platform's moving patterns are very similar to the ones of the persons. Moreover, this dynamic interaction has been judged naturally by the test subjects, which greatly increases the perceived intelligence of the robot.},
author = {Althaus, Philipp and Ishiguro, Hiroshi and Kanda, Takayuki and Miyashita, Takahiro and Christensen, H.I.},
booktitle = {IEEE Int. Conf. Robot. Autom. 2004. Proceedings. ICRA '04. 2004},
doi = {10.1109/ROBOT.2004.1308100},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Althaus et al. - 2004 - Navigation for human-robot interaction tasks.pdf:pdf},
isbn = {0-7803-8232-3},
keywords = {human-robot,navigation,social},
mendeley-tags = {human-robot,navigation,social},
pages = {1894--1900 Vol.2},
publisher = {IEEE},
title = {{Navigation for human-robot interaction tasks}},
url = {http://www.hichristensen.com/Georgia-HomePage/Publishing{\_}files/hic-papers/althaus-icra2004.pdf http://ieeexplore.ieee.org/document/1308100/},
year = {2004}
}
@inproceedings{kidd2006sociable,
  title={A sociable robot to encourage social interaction among the elderly},
  author={Kidd, Cory D and Taggart, Will and Turkle, Sherry},
  booktitle={Robotics and Automation, 2006. ICRA 2006. Proceedings 2006 IEEE International Conference on},
  pages={3972--3976},
  year={2006},
  organization={IEEE}
}
@article{breazeal2003toward,
  title={Toward sociable robots},
  author={Breazeal, Cynthia},
  journal={Robotics and autonomous systems},
  volume={42},
  number={3-4},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}
@inproceedings{unhelkar2014comparative,
  title={Comparative performance of human and mobile robotic assistants in collaborative fetch-and-deliver tasks},
  author={Unhelkar, Vaibhav V and Siu, Ho Chit and Shah, Julie A},
  booktitle={Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction},
  pages={82--89},
  year={2014},
  organization={ACM}
}
@article{Baker2004,
abstract = {Studies of human-robot interaction have shown that operators rely heavily upon the video stream, to the exclusion of all other information on the interface. We have created a new interface that fuses information on and around the video window to exploit this fact.},
author = {Baker, Michael and Casey, Robert and Keyes, Brenden and Yanco, Holly A.},
doi = {10.1109/ICSMC.2004.1400783},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Baker et al. - 2004 - Improved interfaces for human-robot interaction in urban search and rescue.pdf:pdf},
isbn = {0780385667},
issn = {1062922X},
journal = {Conf. Proc. - IEEE Int. Conf. Syst. Man Cybern.},
keywords = {Human-robot interaction,Search and rescue,usar,ux},
mendeley-tags = {usar,ux},
pages = {2960--2965},
pmid = {359950},
title = {{Improved interfaces for human-robot interaction in urban search and rescue}},
volume = {3},
year = {2004}
}
@article{Casper2003,
abstract = {The World Trade Center (WTC) rescue response provided an unfortunate opportunity to study the human-robot interactions (HRI) during a real unstaged rescue for the first time. A post-hoc analysis was performed on the data collected during the response, which resulted in 17 findings on the impact of the environment and conditions on the HRI: the skills displayed and needed by robots and humans, the details of the Urban Search and Rescue (USAR) task, the social informatics in the USAR domain, and what information is communicated at what time. The results of this work impact the field of robotics by providing a case study for HRI in USAR drawn from an unstaged USAR effort. Eleven recommendations are made based on the findings that impact the robotics, computer science, engineering, psychology, and rescue fields. These recommendations call for group organization and user confidence studies, more research into perceptual and assistive interfaces, and formal models of the state of the robot, state of the world, and information as to what has been observed.},
author = {Casper, Jennifer and Murphy, Robin Roberson},
doi = {10.1109/TSMCB.2003.811794},
file = {:C$\backslash$:/Users/pripa/Google Drive/Mendeley/Casper, Murphy - 2003 - Human-robot interactions during the robot-assisted urban search and rescue response at the World Trade Center.pdf:pdf},
isbn = {9780470132531},
issn = {10834419},
journal = {IEEE Trans. Syst. Man, Cybern. Part B Cybern.},
keywords = {Human-robot interaction,Urban search and rescue,World Trade Center (WTC),case-study,usar},
mendeley-tags = {case-study,usar},
number = {3},
pages = {367--385},
pmid = {18238185},
publisher = {IEEE},
title = {{Human-robot interactions during the robot-assisted urban search and rescue response at the World Trade Center}},
volume = {33},
year = {2003}
}
@misc{huttenrauch2001pocketcero,
  title={PocketCERO--mobile interfaces for service robots},
  author={H{\"u}ttenrauch, Helge and Norman, Mikael},
  journal={Proc. of Mobile HCI 2001},
  year={2001},
  publisher={IHM-HCI}
}
@article{billard2004discovering,
  title={Discovering optimal imitation strategies},
  author={Billard, Aude and Epars, Yann and Calinon, Sylvain and Schaal, Stefan and Cheng, Gordon},
  journal={Robotics and autonomous systems},
  volume={47},
  number={2-3},
  pages={69--77},
  year={2004},
  publisher={Elsevier}
}
@article{driewer2005robot,
  title={Robot--human rescue teams: a user requirements analysis},
  author={Driewer, Frauke and Baier, Herbert and Schilling, Klaus},
  journal={Advanced Robotics},
  volume={19},
  number={8},
  pages={819--838},
  year={2005},
  publisher={Taylor \& Francis}
}
@inproceedings{chen2010roboleader,
  title={RoboLeader: An agent for supervisory control of multiple robots},
  author={Chen, Jessie YC and Barnes, Michael J and Qu, Zhihua},
  booktitle={Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction},
  pages={81--82},
  year={2010},
  organization={IEEE Press}
}
@inproceedings{dautenhahn2005robot,
  title={What is a robot companion-friend, assistant or butler?},
  author={Dautenhahn, Kerstin and Woods, Sarah and Kaouri, Christina and Walters, Michael L and Koay, Kheng Lee and Werry, Iain},
  booktitle={Intelligent Robots and Systems, 2005.(IROS 2005). 2005 IEEE/RSJ International Conference on},
  pages={1192--1197},
  year={2005},
  organization={IEEE}
}
@inproceedings{chernova2007confidence,
  title={Confidence-based policy learning from demonstration using gaussian mixture models},
  author={Chernova, Sonia and Veloso, Manuela},
  booktitle={Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
  pages={233},
  year={2007},
  organization={ACM}
}
@article{fitzgerald2018human,
  title={Human-Guided Object Mapping for Task Transfer},
  author={Fitzgerald, Tesca and Goel, Ashok and Thomaz, Andrea},
  journal={ACM Transactions on Human-Robot Interaction (THRI)},
  volume={7},
  number={2},
  pages={17},
  year={2018},
  publisher={ACM}
}
@inproceedings{fitzgerald2016situated,
  title={Situated mapping for transfer learning},
  author={Fitzgerald, Tesca and Bullard, Kalesha and Thomaz, Andrea and Goel, Ashok},
  booktitle={Fourth Annual Conference on Advances in Cognitive Systems},
  year={2016}
}
@inproceedings{fitzgerald2017human,
  title={Human-Robot Co-Creativity: Task Transfer on a Spectrum of Similarity},
  author={Fitzgerald, Tesca and Thomaz, A and Goel, A},
  booktitle={Proceedings of Seventh International Conference on Computational Creativity, Atlanta},
  year={2017}
}
@inproceedings{chao2011towards,
  title={Towards grounding concepts for transfer in goal learning from demonstration},
  author={Chao, Crystal and Cakmak, Maya and Thomaz, Andrea L},
  booktitle={Development and Learning (ICDL), 2011 IEEE International Conference on},
  volume={2},
  pages={1--6},
  year={2011},
  organization={IEEE}
}
@article{hersch2008dynamical,
  title={Dynamical system modulation for robot learning via kinesthetic demonstrations},
  author={Hersch, Micha and Guenter, Florent and Calinon, Sylvain and Billard, Aude},
  journal={IEEE Transactions on Robotics},
  volume={24},
  number={6},
  pages={1463--1467},
  year={2008},
  publisher={IEEE}
}
@article{klein2005common,
  title={Common ground and coordination in joint activity},
  author={Klein, Gary and Feltovich, Paul J and Bradshaw, Jeffrey M and Woods, David D},
  journal={Organizational simulation},
  volume={53},
  pages={139--184},
  year={2005}
}
@inproceedings{stiefelhagen2004natural,
  title={Natural human-robot interaction using speech, head pose and gestures},
  author={Stiefelhagen, Rainer and Fugen, C and Gieselmann, R and Holzapfel, Hartwig and Nickel, Kai and Waibel, Alex},
  booktitle={Intelligent Robots and Systems, 2004.(IROS 2004). Proceedings. 2004 IEEE/RSJ International Conference on},
  volume={3},
  pages={2422--2427},
  year={2004},
  organization={IEEE}
}
@article{breazeal2003emotion,
  title={Emotion and sociable humanoid robots},
  author={Breazeal, Cynthia},
  journal={International Journal of Human-Computer Studies},
  volume={59},
  number={1-2},
  pages={119--155},
  year={2003},
  publisher={Elsevier}
}
@inproceedings{ferrer2013robot,
  title={Robot companion: A social-force based approach with human awareness-navigation in crowded environments},
  author={Ferrer, Gonzalo and Garrell, Anais and Sanfeliu, Alberto},
  booktitle={Intelligent robots and systems (IROS), 2013 IEEE/RSJ international conference on},
  pages={1688--1694},
  year={2013},
  organization={IEEE}
}
@phdthesis{kirby2010social,
  title={Social robot navigation},
  author={Kirby, Rachel},
  year={2010},
  school={Carnegie Mellon University, The Robotics Institute}
}
@article{Nourbakhsh1999,
abstract = {Sage is a robot that has been installed at the Carnegie Museum of Natural History as a full-time autonomous member of the staff. Its goal is to provide educational content to museum visitors in order to augment their museum experience. This paper discusses all aspects of the related research and development. The functional obstacle avoidance system, which departs from the conventional occupancy grid-based approaches, is described. Sage's topological navigation system, using only color vision and odometric information, is also described. Long-term statistics provide a quantitative measure of performance over a nine month trial period. The process by which Sage's educational content and personality were created and evaluated in collaboration with the museum's Divisions of Education and Exhibits is explained. Finally, the ability of Sage to conduct automatic long-term parameter adjustment is presented.},
author = {Nourbakhsh, Illah R. and Bobenage, Judith and Grange, Sebastien and Lutz, Ron and Meyer, Roland and Soto, Alvaro},
doi = {10.1016/S0004-3702(99)00027-2},
file = {:home/zephire/Documents/SortedCRITheses/1999/Nourbakhsh et al. - An affective mobile robot educator with a full-time job.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {docent,seminal},
mendeley-tags = {docent,seminal},
month = {oct},
number = {1-2},
pages = {95--124},
publisher = {Elsevier},
title = {{An affective mobile robot educator with a full-time job}},
url = {https://www.sciencedirect.com/science/article/pii/S0004370299000272},
volume = {114},
year = {1999}
}
@article{grice1975logic,
  title={Logic and conversation},
  author={Grice, H Paul},
  journal={1975},
  pages={41--58},
  year={1975}
}
@article{parashar_goel_sheneman_christensen_2018, title={Towards life-long adaptive agents: using metareasoning for combining knowledge-based planning with situated learning}, volume={33}, DOI={10.1017/S0269888918000279}, journal={The Knowledge Engineering Review}, publisher={Cambridge University Press}, author={Parashar, Priyam and Goel, Ashok K. and Sheneman, Bradley and Christensen, Henrik I.}, year={2018}, pages={e24}}
@article{hall1963system,
  title={A system for the notation of proxemic behavior1},
  author={Hall, Edward T},
  journal={American anthropologist},
  volume={65},
  number={5},
  pages={1003--1026},
  year={1963},
  publisher={Wiley Online Library}
}
@article{stone2000multiagent,
  title={Multiagent systems: A survey from a machine learning perspective},
  author={Stone, Peter and Veloso, Manuela},
  journal={Autonomous Robots},
  volume={8},
  number={3},
  pages={345--383},
  year={2000},
  publisher={Springer}
}
@inproceedings{kruijff2006clarification,
  title={Clarification dialogues in human-augmented mapping},
  author={Kruijff, Geert-Jan M and Zender, Hendrik and Jensfelt, Patric and Christensen, Henrik I},
  booktitle={Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction},
  pages={282--289},
  year={2006},
  organization={ACM}
}
@inproceedings{topp2006topological,
  title={Topological modelling for human augmented mapping},
  author={Topp, Elin A and Christensen, Henrik I},
  booktitle={2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2257--2263},
  year={2006},
  organization={IEEE}
}
@inproceedings{peltason2009mixed,
  title={Mixed-initiative in human augmented mapping},
  author={Peltason, Julia and Siepmann, Frederic HK and Spexard, Thorsten P and Wrede, Britta and Hanheide, Marc and Topp, Elin A},
  booktitle={2009 IEEE International Conference on Robotics and Automation},
  pages={2146--2153},
  year={2009},
  organization={IEEE}
}
@article{topp2010detecting,
  title={Detecting region transitions for human-augmented mapping},
  author={Topp, Elin A and Christensen, Henrik I},
  journal={IEEE Transactions on Robotics},
  volume={26},
  number={4},
  pages={715--720},
  year={2010},
  publisher={IEEE}
}
@article{wickens1998introduction,
  title={An introduction to human factors engineering},
  author={Wickens, Christopher D and Gordon, Sallie E and Liu, Yili and others},
  year={1998},
  publisher={Longman New York}
}
@inproceedings{gombolay2016apprenticeship,
  title={Apprenticeship scheduling: Learning to schedule from human experts},
  author={Gombolay, Matthew and Jensen, Reed and Stigile, Jessica and Son, Sung-Hyun and Shah, Julie},
  year={2016},
  organization={AAAI Press/International Joint Conferences on Artificial Intelligence}
}
@inproceedings{unhelkar2018learning,
  title={Learning and Communicating the Latent States of Human-Machine Collaboration.},
  author={Unhelkar, Vaibhav V and Shah, Julie A},
  booktitle={IJCAI},
  pages={5789--5790},
  year={2018}
}
@techreport{lin2008autonomous,
  title={Autonomous military robotics: Risk, ethics, and design},
  author={Lin, Patrick and Bekey, George and Abney, Keith},
  year={2008},
  institution={California Polytechnic State Univ San Luis Obispo}
}
@article{korb2005risk,
  title={Risk analysis and safety assessment in surgical robotics: A case study on a biopsy robot},
  author={Korb, W and Kornfeld, M and Birkfellner, W and Boesecke, R and Figl, M and Fuerst, M and Kettenbach, J and Vogler, A and Hassfeld, S and Kornreif, G},
  journal={Minimally Invasive Therapy \& Allied Technologies},
  volume={14},
  number={1},
  pages={23--31},
  year={2005},
  publisher={Taylor \& Francis}
}
@inproceedings{guiochet2010experience,
  title={Experience with model-based user-centered risk assessment for service robots},
  author={Guiochet, Jeremie and Martin-Guillerez, Damien and Powell, David},
  booktitle={2010 IEEE 12th International Symposium on High Assurance Systems Engineering},
  pages={104--113},
  year={2010},
  organization={IEEE}
}
@inproceedings{Beer2017,
  title={Framework for multi-human multi-robot interaction: impact of operational context and team configuration on interaction task demands},
  author={Beer, R.Dirk and Rieth, Cory A. and Tran, Randy and Cook, Maia B.},
  booktitle={2017 AAAI Spring Symposium Series},
  year={2017}
}
@article{mortl2012role,
  title={The role of roles: Physical cooperation between humans and robots},
  author={M{\"o}rtl, Alexander and Lawitzky, Martin and Kucukyilmaz, Ayse and Sezgin, Metin and Basdogan, Cagatay and Hirche, Sandra},
  journal={The International Journal of Robotics Research},
  volume={31},
  number={13},
  pages={1656--1674},
  year={2012},
  publisher={SAGE Publications Sage UK: London, England}
}
@techreport{sheehan2004military,
  title={The military missions and means framework},
  author={Sheehan, Jack H and Deitz, Paul H and Bray, Britt E and Harris, Bruce A and Wong, Alexander B},
  year={2004},
  institution={ARMY MATERIEL SYSTEMS ANALYSIS ACTIVITY ABERDEEN PROVING GROUND MD}
}
@inproceedings{huckaby2012taxonomic,
  title={A taxonomic framework for task modeling and knowledge transfer in manufacturing robotics},
  author={Huckaby, Jacob O'Donnal and Christensen, Henrik I},
  booktitle={Workshops at the Twenty-Sixth AAAI Conference on Artificial Intelligence},
  year={2012}
}
@article{yamada1997human,
  title={Human-robot contact in the safeguarding space},
  author={Yamada, Yoji and Hirasawa, Yasuhiro and Huang, Shengyang and Umetani, Yoji and Suita, Kazutsugu},
  journal={IEEE/ASME transactions on mechatronics},
  volume={2},
  number={4},
  pages={230--236},
  year={1997},
  publisher={IEEE}
}
@inproceedings{kitano1997robocup,
  title={The RoboCup synthetic agent challenge 97},
  author={Kitano, Hiroaki and Tambe, Milind and Stone, Peter and Veloso, Manuela and Coradeschi, Silvia and Osawa, Eiichi and Matsubara, Hitoshi and Noda, Itsuki and Asada, Minoru},
  booktitle={Robot Soccer World Cup},
  pages={62--73},
  year={1997},
  organization={Springer}
}
@inproceedings{li2013communication,
  title={Communication architectures and protocols for networking unmanned aerial vehicles},
  author={Li, Jun and Zhou, Yifeng and Lamont, Louise},
  booktitle={2013 IEEE Globecom Workshops (GC Wkshps)},
  pages={1415--1420},
  year={2013},
  organization={IEEE}
}
@inproceedings{hadfield2016cooperative,
  title={Cooperative inverse reinforcement learning},
  author={Hadfield-Menell, Dylan and Russell, Stuart J and Abbeel, Pieter and Dragan, Anca},
  booktitle={Advances in neural information processing systems},
  pages={3909--3917},
  year={2016}
}
@inproceedings{nikolaidis2017game,
  title={Game-theoretic modeling of human adaptation in human-robot collaboration},
  author={Nikolaidis, Stefanos and Nath, Swaprava and Procaccia, Ariel D and Srinivasa, Siddhartha},
  booktitle={2017 12th ACM/IEEE International Conference on Human-Robot Interaction (HRI},
  pages={323--331},
  year={2017},
  organization={IEEE}
}
